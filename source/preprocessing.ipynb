{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c43b3a",
   "metadata": {},
   "source": [
    "# **Cấu hình file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2b5326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW dir: C:\\Users\\pitou\\Desktop\\Data Mining\\data_raw\n",
      "PARQUET dir: C:\\Users\\pitou\\Desktop\\Data Mining\\data_parquet\n",
      "CLEAN dir: C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\n",
      "Files: {'branches': 'branches.csv', 'customers': 'customers.csv', 'orders': 'orders.csv', 'order_details': 'order_details.csv', 'categories': 'categories.csv'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_RAW = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_raw\")\n",
    "DATA_PARQUET = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_parquet\")\n",
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "\n",
    "DATA_PARQUET.mkdir(parents=True, exist_ok=True)\n",
    "DATA_CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = {\n",
    "    'branches':      'branches.csv',\n",
    "    'customers':     'customers.csv',\n",
    "    'orders':        'orders.csv',\n",
    "    'order_details': 'order_details.csv',\n",
    "    'categories':    'categories.csv',\n",
    "}\n",
    "\n",
    "def p(path: Path) -> str:\n",
    "    return path.resolve().as_posix()\n",
    "\n",
    "print('RAW dir:', DATA_RAW.resolve())\n",
    "print('PARQUET dir:', DATA_PARQUET.resolve())\n",
    "print('CLEAN dir:', DATA_CLEAN.resolve())\n",
    "print('Files:', FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84807f6",
   "metadata": {},
   "source": [
    "# **Chuyển CSV sang Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d338875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting branches.csv → branches_raw.parquet\n",
      "→ Converting customers.csv → customers_raw.parquet\n",
      "→ Converting orders.csv → orders_raw.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad92664f08b4b0ba8cec79d09ed6bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting order_details.csv → order_details_raw.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad57c8d5a4264ba889808f20e84ddfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting categories.csv → categories_raw.parquet\n",
      "Convert CSV to Parquet done.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "def csv_to_parquet(csv_path: Path, parquet_path: Path):\n",
    "    sql = f'''\n",
    "    COPY (\n",
    "        SELECT * FROM read_csv_auto('{p(csv_path)}', ALL_VARCHAR=TRUE)\n",
    "    )\n",
    "    TO '{p(parquet_path)}' (FORMAT 'parquet');\n",
    "    '''\n",
    "    con.execute(sql)\n",
    "\n",
    "for key, fname in FILES.items():\n",
    "    csv_fp = DATA_RAW / fname\n",
    "    if not csv_fp.exists():\n",
    "        print(f'Missing CSV: {csv_fp}.')\n",
    "        continue\n",
    "    out_fp = DATA_PARQUET / f'{key}_raw.parquet'\n",
    "    print(f'→ Converting {csv_fp.name} → {out_fp.name}')\n",
    "    csv_to_parquet(csv_fp, out_fp)\n",
    "print('Convert CSV to Parquet done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ce06f",
   "metadata": {},
   "source": [
    "# **Làm sạch dữ liệu với Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58569998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "def rename_if_present(df: pl.DataFrame | pl.LazyFrame, mapping: dict) -> pl.LazyFrame:\n",
    "    current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
    "    safe_map = {old: new for old, new in mapping.items() if old in current_cols}\n",
    "    return df.rename(safe_map)\n",
    "\n",
    "def strip_all_str(df: pl.LazyFrame, cols: list[str]) -> pl.LazyFrame:\n",
    "    ex_cols = [c for c in cols if c in df.columns]\n",
    "    return df.with_columns([pl.col(c).cast(pl.Utf8, strict=False).str.strip_chars().alias(c) for c in ex_cols])\n",
    "\n",
    "def cast_if_present(df: pl.LazyFrame, col: str, dtype) -> pl.LazyFrame:\n",
    "    return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
    "\n",
    "def write_lazy(df_lazy: pl.LazyFrame, out_path: Path):\n",
    "    df_lazy.sink_parquet(p(out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0037e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branches -> branches_clean.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:4: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:9: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  ex_cols = [c for c in cols if c in df.columns]\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\333551156.py:25: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'branch_id' in df.columns:\n"
     ]
    }
   ],
   "source": [
    "# BRANCHES\n",
    "raw_fp = DATA_PARQUET / 'branches_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'branches_clean.parquet'\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'BRANCH_ID': 'branch_id',\n",
    "        'REGION': 'region',\n",
    "        'CITY': 'city',\n",
    "        'TOWN': 'town',\n",
    "        'BRANCH_TOWN': 'branch_town',\n",
    "        'LAT': 'lat',\n",
    "        'LON': 'lon',\n",
    "    })\n",
    "\n",
    "    # Làm sạch text cho các cột string\n",
    "    df = strip_all_str(df, ['branch_id', 'region', 'city', 'town', 'branch_town'])\n",
    "\n",
    "    # Ép kiểu cho ID và số\n",
    "    df = cast_if_present(df, 'branch_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'lat', pl.Float64)\n",
    "    df = cast_if_present(df, 'lon', pl.Float64)\n",
    "\n",
    "    # Loại bỏ dòng trùng theo branch_id nếu có\n",
    "    if 'branch_id' in df.columns:\n",
    "        df = df.unique(subset=['branch_id'])\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    print('branches ->', out_fp.name)\n",
    "else:\n",
    "    print('branches_raw.parquet not found, skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bfd9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers -> customers_clean.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:4: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:9: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  ex_cols = [c for c in cols if c in df.columns]\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\134218845.py:29: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'birth_date' in df.columns:\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\134218845.py:35: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'user_id' in df.columns:\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMERS\n",
    "raw_fp = DATA_PARQUET / 'customers_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'customers_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'USERID': 'user_id',\n",
    "        'USERNAME_': 'username',\n",
    "        'NAMESURNAME': 'name_surname',\n",
    "        'STATUS_': 'status',\n",
    "        'USERGENDER': 'gender',\n",
    "        'USERBIRTHDATE': 'birth_date',\n",
    "        'REGION': 'region',\n",
    "        'CITY': 'city',\n",
    "        'TOWN': 'town',\n",
    "        'DISTRICT': 'district',\n",
    "        'ADDRESSTEXT': 'address_text',\n",
    "    })\n",
    "\n",
    "    # Làm sạch chuỗi cho các cột text\n",
    "    text_cols = ['username', 'name_surname', 'gender', 'region', 'city', 'town', 'district', 'address_text']\n",
    "    df = strip_all_str(df, text_cols)\n",
    "\n",
    "    # Ép kiểu user_id -> string\n",
    "    df = cast_if_present(df, 'user_id', pl.Utf8)\n",
    "\n",
    "    # Parse ngày sinh\n",
    "    if 'birth_date' in df.columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col('birth_date').str.strptime(pl.Date, format='%Y-%m-%d', strict=False)\n",
    "        )\n",
    "\n",
    "    # Loại bỏ trùng user_id nếu có\n",
    "    if 'user_id' in df.columns:\n",
    "        df = df.unique(subset=['user_id'])\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    print('customers ->', out_fp.name)\n",
    "else:\n",
    "    print('customers_raw.parquet not found, skipped.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e324b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:4: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:9: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  ex_cols = [c for c in cols if c in df.columns]\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\2968886750.py:25: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'order_date' in df.columns:\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\2968886750.py:31: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'total_basket' in df.columns:\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\2968886750.py:40: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'order_id' in df.columns:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders -> orders_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# ORDERS\n",
    "raw_fp = DATA_PARQUET / 'orders_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'orders_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'ORDERID': 'order_id',\n",
    "        'BRANCH_ID': 'branch_id',\n",
    "        'DATE_': 'order_date',\n",
    "        'USERID': 'user_id',\n",
    "        'NAMESURNAME': 'name_surname',\n",
    "        'TOTALBASKET': 'total_basket',\n",
    "    })\n",
    "\n",
    "    # Làm sạch text\n",
    "    df = strip_all_str(df, ['branch_id', 'name_surname'])\n",
    "\n",
    "    # Ép kiểu ID về string\n",
    "    df = cast_if_present(df, 'order_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'user_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'branch_id', pl.Utf8)\n",
    "\n",
    "    # Parse ngày\n",
    "    if 'order_date' in df.columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col('order_date').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S', strict=False)\n",
    "        )\n",
    "\n",
    "    # Xử lý cột total_basket\n",
    "    if 'total_basket' in df.columns:\n",
    "        df = df.with_columns(\n",
    "            pl.col('total_basket')\n",
    "            .cast(pl.Utf8, strict=False)\n",
    "            .str.replace_all(\",\", \".\")\n",
    "            .cast(pl.Float64, strict=False)\n",
    "        )\n",
    "\n",
    "    # Loại bỏ trùng order_id nếu có\n",
    "    if 'order_id' in df.columns:\n",
    "        df = df.unique(subset=['order_id'])\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    print('orders ->', out_fp.name)\n",
    "else:\n",
    "    print('orders_raw.parquet not found, skipped.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35cf1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:4: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\1482138606.py:24: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'amount' in df.columns:\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\1482138606.py:29: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if col in df.columns:\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\1482138606.py:45: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if {'amount', 'unit_price', 'total_price'}.issubset(df.columns):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_details -> order_details_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# ORDER_DETAILS\n",
    "raw_fp = DATA_PARQUET / 'order_details_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'order_details_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'ORDERID': 'order_id',\n",
    "        'ORDERDETAILID': 'order_detail_id',\n",
    "        'AMOUNT': 'amount',\n",
    "        'UNITPRICE': 'unit_price',\n",
    "        'TOTALPRICE': 'total_price',\n",
    "        'ITEMID': 'item_id',\n",
    "        'ITEMCODE': 'item_code',\n",
    "    })\n",
    "\n",
    "    # Ép kiểu các ID sang chuỗi\n",
    "    df = cast_if_present(df, 'order_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'order_detail_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'item_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'item_code', pl.Utf8)\n",
    "\n",
    "    # Ép kiểu số lượng\n",
    "    if 'amount' in df.columns:\n",
    "        df = df.with_columns(pl.col('amount').cast(pl.Int64, strict=False))\n",
    "\n",
    "    # Xử lý các cột số có dấu phẩy (unit_price, total_price)\n",
    "    for col in ['unit_price', 'total_price']:\n",
    "        if col in df.columns:\n",
    "            df = df.with_columns(\n",
    "                pl.col(col)\n",
    "                .cast(pl.Utf8, strict=False)\n",
    "                .str.replace_all(\",\", \".\")\n",
    "                .cast(pl.Float64, strict=False)\n",
    "            )\n",
    "\n",
    "    # Loại bỏ dòng không hợp lệ (amount <= 0 hoặc giá null)\n",
    "    df = df.filter(\n",
    "        (pl.col('amount') > 0)\n",
    "        & (pl.col('unit_price').is_not_null())\n",
    "        & (pl.col('total_price').is_not_null())\n",
    "    )\n",
    "\n",
    "    # Kiểm tra tính nhất quán giữa total_price và amount * unitprice\n",
    "    if {'amount', 'unit_price', 'total_price'}.issubset(df.columns):\n",
    "        df = df.with_columns(\n",
    "            (pl.col('amount') * pl.col('unit_price')).alias('calc_line_total')\n",
    "        )\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    print('order_details ->', out_fp.name)\n",
    "else:\n",
    "    print('order_details_raw.parquet not found, skipped.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51082ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories -> categories_clean.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:4: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  current_cols = set(df.columns) if isinstance(df, pl.DataFrame) else set(df.columns)\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:9: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  ex_cols = [c for c in cols if c in df.columns]\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\3853136603.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  return df.with_columns(pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(dtype, strict=False)).otherwise(pl.lit(None)).alias(col)) if col in df.columns else df\n",
      "C:\\Users\\pitou\\AppData\\Local\\Temp\\ipykernel_3964\\2775043055.py:35: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  if 'item_id' in df.columns:\n"
     ]
    }
   ],
   "source": [
    "# CATEGORIES\n",
    "raw_fp = DATA_PARQUET / 'categories_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'categories_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'ITEMID': 'item_id',\n",
    "        'CATEGORY1': 'category1',\n",
    "        'CATEGORY1_ID': 'category1_id',\n",
    "        'CATEGORY2': 'category2',\n",
    "        'CATEGORY2_ID': 'category2_id',\n",
    "        'CATEGORY3': 'category3',\n",
    "        'CATEGORY3_ID': 'category3_id',\n",
    "        'CATEGORY4': 'category4',\n",
    "        'CATEGORY4_ID': 'category4_id',\n",
    "        'BRAND': 'brand',\n",
    "        'ITEMCODE': 'item_code',\n",
    "        'ITEMNAME': 'item_name',\n",
    "    })\n",
    "\n",
    "    # Làm sạch chuỗi cho tất cả các cột text\n",
    "    text_cols = [\n",
    "        'category1', 'category2', 'category3', 'category4',\n",
    "        'brand', 'item_name'\n",
    "    ]\n",
    "    df = strip_all_str(df, text_cols)\n",
    "\n",
    "    # Ép kiểu ID về chuỗi\n",
    "    id_cols = ['item_id', 'item_code', 'category1_id', 'category2_id', 'category3_id', 'category4_id']\n",
    "    for c in id_cols:\n",
    "        df = cast_if_present(df, c, pl.Utf8)\n",
    "\n",
    "    # Loại bỏ dòng trùng item_id nếu có\n",
    "    if 'item_id' in df.columns:\n",
    "        df = df.unique(subset=['item_id'])\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    print('categories ->', out_fp.name)\n",
    "else:\n",
    "    print('categories_raw.parquet not found, skipped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27897860",
   "metadata": {},
   "source": [
    "# **Kiểm tra nhanh thông tin các bảng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c2395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— branches: 161 rows\n",
      "shape: (5, 7)\n",
      "┌───────────┬────────────┬───────────┬───────────────────┬───────────────────┬──────────┬──────────┐\n",
      "│ branch_id ┆ region     ┆ city      ┆ town              ┆ branch_town       ┆ lat      ┆ lon      │\n",
      "│ ---       ┆ ---        ┆ ---       ┆ ---               ┆ ---               ┆ ---      ┆ ---      │\n",
      "│ str       ┆ str        ┆ str       ┆ str               ┆ str               ┆ f64      ┆ f64      │\n",
      "╞═══════════╪════════════╪═══════════╪═══════════════════╪═══════════════════╪══════════╪══════════╡\n",
      "│ 538-KA2   ┆ İç Anadolu ┆ Kayseri   ┆ DEVELİ            ┆ DEVELİ            ┆ 3.8385e9 ┆ 3.5500e9 │\n",
      "│ 132-IS2   ┆ Akdeniz    ┆ Isparta   ┆ GELENDOST         ┆ YALVAÇ            ┆ 3.8124e9 ┆ 3.1011e9 │\n",
      "│ 538-KA1   ┆ İç Anadolu ┆ Kayseri   ┆ AKKIŞLA           ┆ BÜNYAN            ┆ 3.9000e9 ┆ 3.6167e9 │\n",
      "│ 717-ÇA1   ┆ Marmara    ┆ Çanakkale ┆ AYVACIK/ÇANAKKALE ┆ AYVACIK/ÇANAKKALE ┆ 3.9601e9 ┆ 2.6405e9 │\n",
      "│ 310-BA1   ┆ Ege        ┆ Balıkesir ┆ BALIKESİR MERKEZ  ┆ BALIKESİR MERKEZ  ┆ 3.9648e9 ┆ 2.7883e9 │\n",
      "└───────────┴────────────┴───────────┴───────────────────┴───────────────────┴──────────┴──────────┘\n",
      "— customers: 99998 rows\n",
      "shape: (5, 11)\n",
      "┌─────────┬────────────┬────────────┬────────┬───┬──────────┬────────────┬────────────┬────────────┐\n",
      "│ user_id ┆ username   ┆ name_surna ┆ status ┆ … ┆ city     ┆ town       ┆ district   ┆ address_te │\n",
      "│ ---     ┆ ---        ┆ me         ┆ ---    ┆   ┆ ---      ┆ ---        ┆ ---        ┆ xt         │\n",
      "│ str     ┆ str        ┆ ---        ┆ str    ┆   ┆ str      ┆ str        ┆ str        ┆ ---        │\n",
      "│         ┆            ┆ str        ┆        ┆   ┆          ┆            ┆            ┆ str        │\n",
      "╞═════════╪════════════╪════════════╪════════╪═══╪══════════╪════════════╪════════════╪════════════╡\n",
      "│ 97467   ┆ nesrin.dem ┆ Nesrin     ┆ 1      ┆ … ┆ İstanbul ┆ FATİH      ┆ KARAGÜMRÜK ┆ KARAGÜMRÜK │\n",
      "│         ┆ irtas70089 ┆ Demirtaş   ┆        ┆   ┆          ┆            ┆ MAH.       ┆ MAH. VİRAN │\n",
      "│         ┆ @hotmailia ┆            ┆        ┆   ┆          ┆            ┆            ┆ MESCİDİ …  │\n",
      "│         ┆ …          ┆            ┆        ┆   ┆          ┆            ┆            ┆            │\n",
      "│ 98807   ┆ zeynep.mer ┆ Zeynep     ┆ 1      ┆ … ┆ Ankara   ┆ ETİMESGUT  ┆ BAĞLICA    ┆ BAĞLICA    │\n",
      "│         ┆ ve.erdogan ┆ Merve      ┆        ┆   ┆          ┆            ┆ MAH.       ┆ MAH. 1344. │\n",
      "│         ┆ 89007@inbo ┆ Erdoğan    ┆        ┆   ┆          ┆            ┆            ┆ SOKAK      │\n",
      "│         ┆ …          ┆            ┆        ┆   ┆          ┆            ┆            ┆ 0679…      │\n",
      "│ 95196   ┆ hakan.ozde ┆ Hakan      ┆ 1      ┆ … ┆ Samsun   ┆ CANİK      ┆ TOPTEPE    ┆ TOPTEPE    │\n",
      "│         ┆ mir4217@ho ┆ Özdemir    ┆        ┆   ┆          ┆            ┆ MAH.       ┆ MAH.       │\n",
      "│         ┆ tmailia.co ┆            ┆        ┆   ┆          ┆            ┆            ┆ TAŞKIN     │\n",
      "│         ┆ …          ┆            ┆        ┆   ┆          ┆            ┆            ┆ PAŞA       │\n",
      "│         ┆            ┆            ┆        ┆   ┆          ┆            ┆            ┆ SOKAK…     │\n",
      "│ 97187   ┆ alp.sercan ┆ Alp Sercan ┆ 1      ┆ … ┆ Adıyaman ┆ ADIYAMAN   ┆ BAHÇELİEVL ┆ BAHÇELİEVL │\n",
      "│         ┆ .kalayci41 ┆ Kalaycı    ┆        ┆   ┆          ┆ MERKEZ     ┆ ER MAH.    ┆ ER MAH.    │\n",
      "│         ┆ 729@yahoot ┆            ┆        ┆   ┆          ┆            ┆            ┆ 955. SOKAK │\n",
      "│         ┆ …          ┆            ┆        ┆   ┆          ┆            ┆            ┆ …          │\n",
      "│ 97605   ┆ esila.ece. ┆ Esila Ece  ┆ 1      ┆ … ┆ Ankara   ┆ GÖLBAŞI/AN ┆ KARŞIYAKA  ┆ KARŞIYAKA  │\n",
      "│         ┆ turkmen985 ┆ Türkmen    ┆        ┆   ┆          ┆ KARA       ┆ MAH.       ┆ MAH. ESKİ  │\n",
      "│         ┆ 91@inboxpl ┆            ┆        ┆   ┆          ┆            ┆            ┆ DOSTLAR    │\n",
      "│         ┆ …          ┆            ┆        ┆   ┆          ┆            ┆            ┆ Sİ…        │\n",
      "└─────────┴────────────┴────────────┴────────┴───┴──────────┴────────────┴────────────┴────────────┘\n",
      "— orders: 10235193 rows\n",
      "shape: (5, 6)\n",
      "┌──────────┬───────────┬─────────────────────┬─────────┬─────────────────────┬──────────────┐\n",
      "│ order_id ┆ branch_id ┆ order_date          ┆ user_id ┆ name_surname        ┆ total_basket │\n",
      "│ ---      ┆ ---       ┆ ---                 ┆ ---     ┆ ---                 ┆ ---          │\n",
      "│ str      ┆ str       ┆ datetime[μs]        ┆ str     ┆ str                 ┆ f64          │\n",
      "╞══════════╪═══════════╪═════════════════════╪═════════╪═════════════════════╪══════════════╡\n",
      "│ 5547174  ┆ 667-ZO2   ┆ 2021-11-07 00:00:00 ┆ 25216   ┆ Yasemin Funda Ergin ┆ 273.32       │\n",
      "│ 7631943  ┆ 558-SI1   ┆ 2023-01-03 00:00:00 ┆ 19273   ┆ Gönül Gül           ┆ 1762.67      │\n",
      "│ 3584860  ┆ 335-İZ2   ┆ 2021-09-12 00:00:00 ┆ 17897   ┆ Bülent Orhan        ┆ 2355.23      │\n",
      "│ 7349208  ┆ 734-İS2   ┆ 2022-05-08 00:00:00 ┆ 26151   ┆ Orhan Yalçın        ┆ 1600.22      │\n",
      "│ 1986158  ┆ 734-İS4   ┆ 2022-06-23 00:00:00 ┆ 54077   ┆ Burak Güneş         ┆ 3303.07      │\n",
      "└──────────┴───────────┴─────────────────────┴─────────┴─────────────────────┴──────────────┘\n",
      "— order_details: 51185032 rows\n",
      "shape: (5, 8)\n",
      "┌──────────┬──────────────┬────────┬────────────┬─────────────┬─────────┬───────────┬──────────────┐\n",
      "│ order_id ┆ order_detail ┆ amount ┆ unit_price ┆ total_price ┆ item_id ┆ item_code ┆ calc_line_to │\n",
      "│ ---      ┆ _id          ┆ ---    ┆ ---        ┆ ---         ┆ ---     ┆ ---       ┆ tal          │\n",
      "│ str      ┆ ---          ┆ i64    ┆ f64        ┆ f64         ┆ str     ┆ str       ┆ ---          │\n",
      "│          ┆ str          ┆        ┆            ┆             ┆         ┆           ┆ f64          │\n",
      "╞══════════╪══════════════╪════════╪════════════╪═════════════╪═════════╪═══════════╪══════════════╡\n",
      "│ 5523363  ┆ 27622768     ┆ 4      ┆ 12.5       ┆ 25.96       ┆ 23667   ┆ 40199     ┆ 50.0         │\n",
      "│ 5503074  ┆ 27521136     ┆ 3      ┆ 3.5        ┆ 10.08       ┆ 1324    ┆ 2871      ┆ 10.5         │\n",
      "│ 5582877  ┆ 27921491     ┆ 4      ┆ 4.9        ┆ 35.04       ┆ 4735    ┆ 17605     ┆ 19.6         │\n",
      "│ 5571722  ┆ 27865830     ┆ 8      ┆ 15.5       ┆ 85.84       ┆ 17179   ┆ 32797     ┆ 124.0        │\n",
      "│ 5635480  ┆ 28184303     ┆ 2      ┆ 57.5       ┆ 121.1       ┆ 21009   ┆ 34535     ┆ 115.0        │\n",
      "└──────────┴──────────────┴────────┴────────────┴─────────────┴─────────┴───────────┴──────────────┘\n",
      "— categories: 27000 rows\n",
      "shape: (5, 12)\n",
      "┌─────────┬───────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ item_id ┆ category1 ┆ category1_ ┆ category2 ┆ … ┆ category4 ┆ brand     ┆ item_code ┆ item_name │\n",
      "│ ---     ┆ ---       ┆ id         ┆ ---       ┆   ┆ _id       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str     ┆ str       ┆ ---        ┆ str       ┆   ┆ ---       ┆ str       ┆ str       ┆ str       │\n",
      "│         ┆           ┆ str        ┆           ┆   ┆ str       ┆           ┆           ┆           │\n",
      "╞═════════╪═══════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 25483   ┆ EV        ┆ 627999999  ┆ KITAP-DER ┆ … ┆ 71-609792 ┆ KITAPLAR  ┆ 41492     ┆ KENDINE   │\n",
      "│         ┆           ┆            ┆ GI-KIRTAS ┆   ┆ 23        ┆           ┆           ┆ GIDEN YOL │\n",
      "│         ┆           ┆            ┆ IYE       ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 26632   ┆ EV        ┆ 627999999  ┆ KITAP-DER ┆ … ┆ 70-602399 ┆ KIRTASIYE ┆ 37330     ┆ GIPTA     │\n",
      "│         ┆           ┆            ┆ GI-KIRTAS ┆   ┆ 70        ┆ LER       ┆           ┆ FINELINER │\n",
      "│         ┆           ┆            ┆ IYE       ┆   ┆           ┆           ┆           ┆ 0.4 MM    │\n",
      "│         ┆           ┆            ┆           ┆   ┆           ┆           ┆           ┆ RENKLI …  │\n",
      "│ 25505   ┆ EV        ┆ 627999999  ┆ TEKSTIL-G ┆ … ┆ 74-232316 ┆ GEZER     ┆ 41516     ┆ GEZER     │\n",
      "│         ┆           ┆            ┆ IYIM-AKSE ┆   ┆ 629       ┆           ┆           ┆ 9018 KOLL │\n",
      "│         ┆           ┆            ┆ SUAR      ┆   ┆           ┆           ┆           ┆ EKSYN.    │\n",
      "│         ┆           ┆            ┆           ┆   ┆           ┆           ┆           ┆ MERDANE … │\n",
      "│ 26678   ┆ EV        ┆ 627999999  ┆ KITAP-DER ┆ … ┆ 71-609792 ┆ KITAPLAR  ┆ 37388     ┆ KALIN CEP │\n",
      "│         ┆           ┆            ┆ GI-KIRTAS ┆   ┆ 23        ┆           ┆           ┆ KITAPLARI │\n",
      "│         ┆           ┆            ┆ IYE       ┆   ┆           ┆           ┆           ┆ /COCUK    │\n",
      "│         ┆           ┆            ┆           ┆   ┆           ┆           ┆           ┆ GEZ…      │\n",
      "│ 25322   ┆ DETERJAN  ┆ 5624621    ┆ CAMASIR   ┆ … ┆ 48-277523 ┆ BINGO     ┆ 41193     ┆ BINGO     │\n",
      "│         ┆           ┆            ┆ YIKAMA    ┆   ┆ 31        ┆           ┆           ┆ AUTOMAT 4 │\n",
      "│         ┆           ┆            ┆           ┆   ┆           ┆           ┆           ┆ KG ULTRA  │\n",
      "│         ┆           ┆            ┆           ┆   ┆           ┆           ┆           ┆ BEYAZ…    │\n",
      "└─────────┴───────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "branches.branch_id appears unique\n",
      "customers.customer_id appears unique\n",
      "orders.order_id appears unique\n",
      "categories.category_id appears unique\n",
      "Validation pass finished.\n"
     ]
    }
   ],
   "source": [
    "def safe_scan(path: Path):\n",
    "    return pl.scan_parquet(p(path)) if path.exists() else None\n",
    "\n",
    "checks = {}\n",
    "for name in ['branches', 'customers', 'orders', 'order_details', 'categories']:\n",
    "    fp = DATA_CLEAN / f'{name}_clean.parquet'\n",
    "    df = safe_scan(fp)\n",
    "    if df is None:\n",
    "        print(f'Missing {fp.name}')\n",
    "        continue\n",
    "    head = df.head(5).collect()\n",
    "    rows = df.select(pl.len()).collect().item()\n",
    "    checks[name] = {'rows': rows, 'sample': head}\n",
    "\n",
    "    print(f'— {name}: {rows} rows')\n",
    "    print(head)\n",
    "\n",
    "def check_unique(df_lazy: pl.LazyFrame, key: str):\n",
    "    if df_lazy is None or key not in df_lazy.collect_schema().names():\n",
    "        return None\n",
    "\n",
    "    dup = (\n",
    "        df_lazy\n",
    "        .group_by(key)\n",
    "        .agg(pl.len().alias(\"count\"))\n",
    "        .filter(pl.col(\"count\") > 1)\n",
    "        .limit(5)\n",
    "        .collect()\n",
    "    )\n",
    "    return dup\n",
    "\n",
    "for name, key in [('branches','branch_id'), ('customers','customer_id'), ('orders','order_id'), ('categories','category_id')]:\n",
    "    fp = DATA_CLEAN / f'{name}_clean.parquet'\n",
    "    df = safe_scan(fp)\n",
    "    if df is None:\n",
    "        continue\n",
    "    dup = check_unique(df, key)\n",
    "    if dup is not None and dup.height > 0:\n",
    "        print(f'Duplicates in {name}.{key}:')\n",
    "        print(dup)\n",
    "    else:\n",
    "        print(f'{name}.{key} appears unique')\n",
    "\n",
    "print('Validation pass finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db354aac",
   "metadata": {},
   "source": [
    "# **Tiền xử lý dữ liệu từng file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7dfc320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tiền xử lý xong branches\n"
     ]
    }
   ],
   "source": [
    "# BRANCHES\n",
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "branches_fp = DATA_CLEAN / \"branches_clean.parquet\"\n",
    "\n",
    "if branches_fp.exists():\n",
    "    df = pl.read_parquet(str(branches_fp))\n",
    "\n",
    "    # Scale lat/lon\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"lat\") / 1e8).alias(\"lat\"),\n",
    "        (pl.col(\"lon\") / 1e8).alias(\"lon\")\n",
    "    ])\n",
    "\n",
    "    # Chuẩn hóa chuỗi, thay null\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"region\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "        pl.col(\"city\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "        pl.col(\"town\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "    ])\n",
    "\n",
    "    # Loại dòng thiếu branch_id\n",
    "    df = df.filter(pl.col(\"branch_id\").is_not_null())\n",
    "\n",
    "    # Ghi đè lại file clean\n",
    "    df.write_parquet(str(branches_fp))\n",
    "    print(\"Đã tiền xử lý xong branches\")\n",
    "else:\n",
    "    print(\"Không tìm thấy branches_clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "859dd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tiền xử lý xong orders\n"
     ]
    }
   ],
   "source": [
    "# ORDERS\n",
    "orders_fp = DATA_CLEAN / \"orders_clean.parquet\"\n",
    "\n",
    "if orders_fp.exists():\n",
    "    df = pl.read_parquet(str(orders_fp))\n",
    "\n",
    "    # Loại order thiếu user_id hoặc branch_id\n",
    "    df = df.filter(\n",
    "        pl.col(\"user_id\").is_not_null() & pl.col(\"branch_id\").is_not_null()\n",
    "    )\n",
    "\n",
    "    # Loại order có total_basket <= 0 hoặc null\n",
    "    if \"total_basket\" in df.columns:\n",
    "        df = df.filter(pl.col(\"total_basket\").is_not_null() & (pl.col(\"total_basket\") > 0))\n",
    "\n",
    "    if \"order_date\" in df.columns:\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"order_date\").dt.year().alias(\"order_year\"),\n",
    "            pl.col(\"order_date\").dt.month().alias(\"order_month\"),\n",
    "            pl.col(\"order_date\").dt.weekday().alias(\"order_weekday\")\n",
    "        ])\n",
    "\n",
    "    df.write_parquet(str(orders_fp))\n",
    "    print(\"Đã tiền xử lý xong orders\")\n",
    "else:\n",
    "    print(\"Không tìm thấy orders_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435949fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tiền xử lý xong order_details\n"
     ]
    }
   ],
   "source": [
    "# ORDER_DETAILS\n",
    "details_fp = DATA_CLEAN / \"order_details_clean.parquet\"\n",
    "\n",
    "if details_fp.exists():\n",
    "    df = pl.read_parquet(str(details_fp))\n",
    "\n",
    "    # Loại dòng amount <= 0 hoặc null\n",
    "    df = df.filter(pl.col(\"amount\").is_not_null() & (pl.col(\"amount\") > 0))\n",
    "\n",
    "    # Loại dòng unit_price hoặc total_price <= 0 hoặc null\n",
    "    df = df.filter(\n",
    "        pl.col(\"unit_price\").is_not_null() & (pl.col(\"unit_price\") > 0) &\n",
    "        pl.col(\"total_price\").is_not_null() & (pl.col(\"total_price\") > 0)\n",
    "    )\n",
    "\n",
    "    # Kiểm tra sai lệch giữa total_price và amount*unit_price\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"amount\") * pl.col(\"unit_price\") - pl.col(\"total_price\")).alias(\"price_diff\")\n",
    "    )\n",
    "    df = df.filter(pl.col(\"price_diff\").abs() < 1e-2)  # loại dòng sai số lớn\n",
    "\n",
    "    df = df.drop(\"price_diff\")\n",
    "\n",
    "    df.write_parquet(str(details_fp))\n",
    "    print(\"Đã tiền xử lý xong order_details\")\n",
    "else:\n",
    "    print(\"Không tìm thấy order_details_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b103f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tiền xử lý xong categories\n"
     ]
    }
   ],
   "source": [
    "# CATEGORIES\n",
    "categories_fp = DATA_CLEAN / \"categories_clean.parquet\"\n",
    "\n",
    "if categories_fp.exists():\n",
    "    df = pl.read_parquet(str(categories_fp))\n",
    "\n",
    "    # Loại null item_id\n",
    "    df = df.filter(pl.col(\"item_id\").is_not_null())\n",
    "\n",
    "    # Chuẩn hóa category / brand / item_name\n",
    "    for c in [\"category1\",\"category2\",\"category3\",\"category4\",\"brand\",\"item_name\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.with_columns(pl.col(c).fill_null(\"Unknown\").str.strip_chars())\n",
    "\n",
    "    df.write_parquet(str(categories_fp))\n",
    "    print(\"Đã tiền xử lý xong categories\")\n",
    "else:\n",
    "    print(\"Không tìm thấy categories_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5631efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_all  n_zero  pct_zero\n",
      "0  69125     0.0       0.0\n",
      "   n_sus  sum_total_price_sus\n",
      "0      0                  NaN\n",
      "   n_free  qty_free\n",
      "0       0       NaN\n",
      "Empty DataFrame\n",
      "Columns: [item_id, item_name, brand, cnt]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "od = (DATA_CLEAN / \"order_details_clean.parquet\").as_posix()\n",
    "cat = (DATA_CLEAN / \"categories_clean.parquet\").as_posix()\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Tỷ lệ dòng có unit_price = 0\n",
    "res1 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_all,\n",
    "  SUM(CASE WHEN unit_price = 0 THEN 1 ELSE 0 END) AS n_zero,\n",
    "  100.0 * SUM(CASE WHEN unit_price = 0 THEN 1 ELSE 0 END) / COUNT(*) AS pct_zero\n",
    "FROM parquet_scan('{od}');\n",
    "\"\"\").fetchdf()\n",
    "print(res1)\n",
    "\n",
    "# unit_price = 0 nhưng total_price > 0\n",
    "res2 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_sus,\n",
    "  SUM(total_price) AS sum_total_price_sus\n",
    "FROM parquet_scan('{od}')\n",
    "WHERE unit_price = 0 AND total_price > 0;\n",
    "\"\"\").fetchdf()\n",
    "print(res2)\n",
    "\n",
    "# unit_price = 0 và total_price = 0 (amount > 0)\n",
    "res3 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_free,\n",
    "  SUM(amount) AS qty_free\n",
    "FROM parquet_scan('{od}')\n",
    "WHERE unit_price = 0 AND total_price = 0 AND amount > 0;\n",
    "\"\"\").fetchdf()\n",
    "print(res3)\n",
    "\n",
    "# Top mặt hàng có unit_price = 0\n",
    "res4 = con.execute(f\"\"\"\n",
    "SELECT d.item_id, c.item_name, c.brand, COUNT(*) AS cnt\n",
    "FROM parquet_scan('{od}') d\n",
    "LEFT JOIN parquet_scan('{cat}') c ON d.item_id = c.item_id\n",
    "WHERE d.unit_price = 0\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY cnt DESC\n",
    "LIMIT 20;\n",
    "\"\"\").fetchdf()\n",
    "print(res4)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097b7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
