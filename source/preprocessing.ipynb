{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c43b3a",
   "metadata": {},
   "source": [
    "# **Cấu hình file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2b5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import duckdb\n",
    "\n",
    "# ===== CẤU HÌNH =====\n",
    "DATA_RAW = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_raw\")\n",
    "DATA_PARQUET = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_parquet\")\n",
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "\n",
    "DATA_PARQUET.mkdir(parents=True, exist_ok=True)\n",
    "DATA_CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = {\n",
    "    'branches': 'branches.csv',\n",
    "    'customers': 'customers.csv',\n",
    "    'orders': 'orders.csv',\n",
    "    'order_details': 'order_details.csv',\n",
    "    'categories': 'categories.csv',\n",
    "}\n",
    "\n",
    "def p(path: Path) -> str:\n",
    "    return path.resolve().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dff6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== UTILITY FUNCTIONS =====\n",
    "def rename_if_present(df: pl.DataFrame | pl.LazyFrame, mapping: dict) -> pl.LazyFrame:\n",
    "    schema = df.collect_schema() if isinstance(df, pl.LazyFrame) else df.schema\n",
    "    safe_map = {old: new for old, new in mapping.items() if old in schema}\n",
    "    return df.rename(safe_map)\n",
    "\n",
    "def strip_all_str(df: pl.LazyFrame, cols: list[str]) -> pl.LazyFrame:\n",
    "    schema = df.collect_schema()\n",
    "    ex_cols = [c for c in cols if c in schema]\n",
    "    return df.with_columns([\n",
    "        pl.col(c).cast(pl.Utf8, strict=False).str.strip_chars().alias(c) \n",
    "        for c in ex_cols\n",
    "    ])\n",
    "\n",
    "def cast_if_present(df: pl.LazyFrame, col: str, dtype) -> pl.LazyFrame:\n",
    "    schema = df.collect_schema()\n",
    "    if col not in schema:\n",
    "        return df\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(col).is_not_null())\n",
    "        .then(pl.col(col).cast(dtype, strict=False))\n",
    "        .otherwise(pl.lit(None))\n",
    "        .alias(col)\n",
    "    )\n",
    "\n",
    "def write_lazy(df_lazy: pl.LazyFrame, out_path: Path):\n",
    "    df_lazy.sink_parquet(p(out_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84807f6",
   "metadata": {},
   "source": [
    "# **Chuyển CSV sang Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d338875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 1: CHUYỂN CSV SANG PARQUET\n",
      "============================================================\n",
      "→ Converting branches.csv → branches_raw.parquet\n",
      "→ Converting customers.csv → customers_raw.parquet\n",
      "→ Converting orders.csv → orders_raw.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc421897c8314917a37fa597bcf9634d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting order_details.csv → order_details_raw.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a79972a55fb46e893b8ae8258a50d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Converting categories.csv → categories_raw.parquet\n",
      "CSV to Parquet done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 1. CSV TO PARQUET =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 1: CHUYỂN CSV SANG PARQUET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "def csv_to_parquet(csv_path: Path, parquet_path: Path):\n",
    "    sql = f'''\n",
    "    COPY (\n",
    "        SELECT * FROM read_csv_auto('{p(csv_path)}', ALL_VARCHAR=TRUE)\n",
    "    )\n",
    "    TO '{p(parquet_path)}' (FORMAT 'parquet');\n",
    "    '''\n",
    "    con.execute(sql)\n",
    "\n",
    "for key, fname in FILES.items():\n",
    "    csv_fp = DATA_RAW / fname\n",
    "    if not csv_fp.exists():\n",
    "        print(f'Missing CSV: {csv_fp}')\n",
    "        continue\n",
    "    out_fp = DATA_PARQUET / f'{key}_raw.parquet'\n",
    "    print(f'→ Converting {csv_fp.name} → {out_fp.name}')\n",
    "    csv_to_parquet(csv_fp, out_fp)\n",
    "\n",
    "print('CSV to Parquet done.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ce06f",
   "metadata": {},
   "source": [
    "# **Làm sạch dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58569998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 2: LÀM SẠCH BRANCHES\n",
      "============================================================\n",
      "Branches cleaned: 161 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 2. CLEAN BRANCHES =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 2: LÀM SẠCH BRANCHES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "raw_fp = DATA_PARQUET / 'branches_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'branches_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'BRANCH_ID': 'branch_id',\n",
    "        'REGION': 'region',\n",
    "        'CITY': 'city',\n",
    "        'TOWN': 'town',\n",
    "        'BRANCH_TOWN': 'branch_town',\n",
    "        'LAT': 'lat',\n",
    "        'LON': 'lon',\n",
    "    })\n",
    "\n",
    "    df = strip_all_str(df, ['branch_id', 'region', 'city', 'town', 'branch_town'])\n",
    "    df = cast_if_present(df, 'branch_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'lat', pl.Float64)\n",
    "    df = cast_if_present(df, 'lon', pl.Float64)\n",
    "\n",
    "    schema = df.collect_schema()\n",
    "    if 'branch_id' in schema:\n",
    "        df = df.unique(subset=['branch_id'])\n",
    "\n",
    "    # Scale lat/lon\n",
    "    if 'lat' in schema and 'lon' in schema:\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"lat\") / 1e8).alias(\"lat\"),\n",
    "            (pl.col(\"lon\") / 1e8).alias(\"lon\")\n",
    "        ])\n",
    "\n",
    "    # Fill null\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"region\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "        pl.col(\"city\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "        pl.col(\"town\").fill_null(\"Unknown\").str.strip_chars(),\n",
    "    ])\n",
    "\n",
    "    # Remove null branch_id\n",
    "    df = df.filter(pl.col(\"branch_id\").is_not_null())\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    cnt = df.select(pl.len()).collect().item()\n",
    "    print(f'Branches cleaned: {cnt:,} rows\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0037e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 3: LÀM SẠCH CUSTOMERS\n",
      "============================================================\n",
      "Customers cleaned: 99,998 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 3. CLEAN CUSTOMERS =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 3: LÀM SẠCH CUSTOMERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "raw_fp = DATA_PARQUET / 'customers_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'customers_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'USERID': 'user_id',\n",
    "        'USERNAME_': 'username',\n",
    "        'NAMESURNAME': 'name_surname',\n",
    "        'STATUS_': 'status',\n",
    "        'USERGENDER': 'gender',\n",
    "        'USERBIRTHDATE': 'birth_date',\n",
    "        'REGION': 'region',\n",
    "        'CITY': 'city',\n",
    "        'TOWN': 'town',\n",
    "        'DISTRICT': 'district',\n",
    "        'ADDRESSTEXT': 'address_text',\n",
    "    })\n",
    "\n",
    "    text_cols = ['username', 'name_surname', 'gender', 'region', 'city', 'town', 'district', 'address_text']\n",
    "    df = strip_all_str(df, text_cols)\n",
    "    df = cast_if_present(df, 'user_id', pl.Utf8)\n",
    "\n",
    "    schema = df.collect_schema()\n",
    "    \n",
    "    if 'birth_date' in schema:\n",
    "        df = df.with_columns(\n",
    "            pl.col('birth_date').str.strptime(pl.Date, format='%Y-%m-%d', strict=False)\n",
    "        )\n",
    "\n",
    "    df = df.filter(pl.col(\"user_id\").is_not_null())\n",
    "    df = df.unique(subset=['user_id'], keep='first')\n",
    "    \n",
    "    # Chuẩn hóa giới tính E = Nam, K = Nữ\n",
    "    if 'gender' in schema:\n",
    "        df = df.with_columns(\n",
    "            pl.when(pl.col('gender').str.to_uppercase() == 'E')\n",
    "              .then(pl.lit('Male'))\n",
    "              .when(pl.col('gender').str.to_uppercase() == 'K')\n",
    "              .then(pl.lit('Female'))\n",
    "              .otherwise(pl.lit('Unknown')) \n",
    "              .alias('gender')\n",
    "        )\n",
    "\n",
    "    for col in ['region', 'city', 'town', 'district']:\n",
    "        if col in schema:\n",
    "            df = df.with_columns(\n",
    "                pl.col(col).fill_null(\"Unknown\").str.strip_chars()\n",
    "            )\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    cnt = df.select(pl.len()).collect().item()\n",
    "    print(f'Customers cleaned: {cnt:,} rows\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfd9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 4: LÀM SẠCH ORDERS\n",
      "============================================================\n",
      "Orders cleaned: 10,235,193 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 4. CLEAN ORDERS =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 4: LÀM SẠCH ORDERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "raw_fp = DATA_PARQUET / 'orders_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'orders_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'ORDERID': 'order_id',\n",
    "        'BRANCH_ID': 'branch_id',\n",
    "        'DATE_': 'order_date',\n",
    "        'USERID': 'user_id',\n",
    "        'NAMESURNAME': 'name_surname',\n",
    "        'TOTALBASKET': 'total_basket',\n",
    "    })\n",
    "\n",
    "    df = strip_all_str(df, ['branch_id', 'name_surname'])\n",
    "    df = cast_if_present(df, 'order_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'user_id', pl.Utf8)\n",
    "    df = cast_if_present(df, 'branch_id', pl.Utf8)\n",
    "\n",
    "    schema = df.collect_schema()\n",
    "    if 'order_date' in schema:\n",
    "        df = df.with_columns(\n",
    "            pl.col('order_date').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S', strict=False)\n",
    "        )\n",
    "\n",
    "    if 'total_basket' in schema:\n",
    "        df = df.with_columns(\n",
    "            pl.col('total_basket')\n",
    "            .cast(pl.Utf8, strict=False)\n",
    "            .str.replace_all(\",\", \".\")\n",
    "            .cast(pl.Float64, strict=False)\n",
    "        )\n",
    "\n",
    "    if 'order_id' in schema:\n",
    "        df = df.unique(subset=['order_id'])\n",
    "\n",
    "    # Filter invalid orders\n",
    "    df = df.filter(\n",
    "        pl.col(\"user_id\").is_not_null() & \n",
    "        pl.col(\"branch_id\").is_not_null()\n",
    "    )\n",
    "\n",
    "    # Chấp nhận total_basket = 0 (có thể là đơn trả hàng/hoàn tiền)\n",
    "    if \"total_basket\" in schema:\n",
    "        df = df.filter(\n",
    "            pl.col(\"total_basket\").is_not_null() & \n",
    "            (pl.col(\"total_basket\") >= 0)  # Thay đổi từ > 0 thành >= 0\n",
    "        )\n",
    "\n",
    "    # Add date features\n",
    "    if \"order_date\" in schema:\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"order_date\").dt.year().alias(\"order_year\"),\n",
    "            pl.col(\"order_date\").dt.month().alias(\"order_month\"),\n",
    "            pl.col(\"order_date\").dt.weekday().alias(\"order_weekday\")\n",
    "        ])\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    cnt = df.select(pl.len()).collect().item()\n",
    "    print(f'Orders cleaned: {cnt:,} rows\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e324b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 5: LÀM SẠCH ORDER_DETAILS\n",
      "============================================================\n",
      "Order_details cleaned: 51,185,032 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 5. CLEAN ORDER_DETAILS =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 5: LÀM SẠCH ORDER_DETAILS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "raw_fp = DATA_PARQUET / 'order_details_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'order_details_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(str(raw_fp))\n",
    "\n",
    "    df = rename_if_present(df, {\n",
    "        'ORDERID': 'order_id',\n",
    "        'ORDERDETAILID': 'order_detail_id',\n",
    "        'AMOUNT': 'amount',\n",
    "        'UNITPRICE': 'unit_price',\n",
    "        'TOTALPRICE': 'total_price',\n",
    "        'ITEMID': 'item_id',\n",
    "        'ITEMCODE': 'item_code',\n",
    "    })\n",
    "\n",
    "    # Ép kiểu dữ liệu\n",
    "    for col in [\"order_id\", \"order_detail_id\", \"item_id\", \"item_code\"]:\n",
    "        df = cast_if_present(df, col, pl.Utf8)\n",
    "    if 'amount' in df.collect_schema().keys():\n",
    "        df = df.with_columns(pl.col('amount').cast(pl.Int64, strict=False))\n",
    "    for col in ['unit_price', 'total_price']:\n",
    "        if col in df.collect_schema().keys():\n",
    "            df = df.with_columns(\n",
    "                pl.col(col).cast(pl.Utf8, strict=False)\n",
    "                .str.replace_all(\",\", \".\").cast(pl.Float64, strict=False)\n",
    "            )\n",
    "\n",
    "    # Chỉ giữ lại các dòng có ID, số lượng và giá > 0 (hoặc >= 0 cho unit_price)\n",
    "    df = df.filter(\n",
    "        pl.col('order_id').is_not_null() &\n",
    "        pl.col('item_id').is_not_null() &\n",
    "        pl.col('amount').is_not_null() & (pl.col('amount') > 0) &\n",
    "        pl.col('unit_price').is_not_null() & (pl.col('unit_price') >= 0) &\n",
    "        pl.col('total_price').is_not_null() & (pl.col('total_price') >= 0)\n",
    "    )\n",
    "    \n",
    "    # total_price là giá trị khách phải trả (sau khi đã áp dụng giảm giá và chiết khấu) và tính toán mức chiết khấu\n",
    "    if {'amount', 'unit_price', 'total_price'}.issubset(df.collect_schema().keys()):\n",
    "        df = df.with_columns(\n",
    "            (pl.col('amount') * pl.col('unit_price') - pl.col('total_price')).alias('discount_amount')\n",
    "        )\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    cnt = df.select(pl.len()).collect().item()\n",
    "    print(f'Order_details cleaned: {cnt:,} rows\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20de4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BƯỚC 6: LÀM SẠCH CATEGORIES\n",
      "============================================================\n",
      "Categories cleaned: 27,000 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 6. CLEAN CATEGORIES =====\n",
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 6: LÀM SẠCH CATEGORIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "raw_fp = DATA_PARQUET / 'categories_raw.parquet'\n",
    "out_fp = DATA_CLEAN / 'categories_clean.parquet'\n",
    "\n",
    "if raw_fp.exists():\n",
    "    df = pl.scan_parquet(p(raw_fp))\n",
    "    df = rename_if_present(df, {\n",
    "        'ITEMID': 'item_id',\n",
    "        'CATEGORY1': 'category1',\n",
    "        'CATEGORY1_ID': 'category1_id',\n",
    "        'CATEGORY2': 'category2',\n",
    "        'CATEGORY2_ID': 'category2_id',\n",
    "        'CATEGORY3': 'category3',\n",
    "        'CATEGORY3_ID': 'category3_id',\n",
    "        'CATEGORY4': 'category4',\n",
    "        'CATEGORY4_ID': 'category4_id',\n",
    "        'BRAND': 'brand',\n",
    "        'ITEMCODE': 'item_code',\n",
    "        'ITEMNAME': 'item_name',\n",
    "    })\n",
    "\n",
    "    text_cols = [\n",
    "        'category1', 'category2', 'category3', 'category4',\n",
    "        'brand', 'item_name'\n",
    "    ]\n",
    "    df = strip_all_str(df, text_cols)\n",
    "\n",
    "    id_cols = ['item_id', 'item_code', 'category1_id', 'category2_id', 'category3_id', 'category4_id']\n",
    "    for c in id_cols:\n",
    "        df = cast_if_present(df, c, pl.Utf8)\n",
    "\n",
    "    schema = df.collect_schema()\n",
    "    if 'item_id' in schema:\n",
    "        df = df.unique(subset=['item_id'])\n",
    "\n",
    "    # Filter null item_id\n",
    "    df = df.filter(pl.col(\"item_id\").is_not_null())\n",
    "\n",
    "    # Chuẩn hóa null values\n",
    "    for c in [\"category1\", \"category2\", \"category3\", \"category4\", \"brand\", \"item_name\"]:\n",
    "        if c in schema:\n",
    "            df = df.with_columns(pl.col(c).fill_null(\"Unknown\").str.strip_chars())\n",
    "\n",
    "    write_lazy(df, out_fp)\n",
    "    cnt = df.select(pl.len()).collect().item()\n",
    "    print(f'Categories cleaned: {cnt:,} rows\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69219db2",
   "metadata": {},
   "source": [
    "# **Kiểm tra nhanh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19966dfc-3886-4978-97ba-c192955ec43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n_all    n_zero  pct_zero\n",
      "0  51185032  115638.0  0.225922\n",
      "   n_sus  sum_total_price_sus\n",
      "0   5346           1304838.63\n",
      "   n_free  qty_free\n",
      "0  110292  496407.0\n",
      "   item_id                             item_name      brand   cnt\n",
      "0     4506               GOLBASI SALATALIK YERLI  SALATALIK  2000\n",
      "1     9921           KAF.DOGADAN YESIL CAY BALLI    DOGADAN  1997\n",
      "2     3235                         PALET 110*130       KARO  1962\n",
      "3     8801         KAF.DOGADAN YESIL CAY GINGOLU    DOGADAN  1960\n",
      "4    12647                 GOLBASI BIBER KIRMIZI      BIBER  1955\n",
      "5    13606             GEZER MERDANE TERLIK 9312      GEZER  1953\n",
      "6      544                   BAKLIYAT KOLI BANDI       SARF  1952\n",
      "7    11677  KAF.NESCAFE 3 IN 1 18 GR BOL KREMALI    NESCAFE  1949\n",
      "8     1025             GOLBASI BIBER KAPYA YESIL      BIBER  1947\n",
      "9      382                         CIMENTO DOKME       KARO  1938\n",
      "10    1319                KAF.DOGADAN FORM LIMON    DOGADAN  1935\n",
      "11   11584         BAHARAT KARTON KUTU BUYUK(KG)       SARF  1934\n",
      "12   22513              SIYAH ÇIMENTO TORBA 42.5       KARO  1934\n",
      "13     520                     GOLBASI ERIK KARA       ERIK  1933\n",
      "14     144                      GOLBASI ELMA YAZ       ELMA  1933\n",
      "15     531                            ELB.KAYISI     KAYISI  1930\n",
      "16     604            BAY.SEK.KENT 1 KG ELBISTAN       KENT  1927\n",
      "17     245                     GOLBASI SUS BIBER      BIBER  1924\n",
      "18    8206         BAHARAT KARTON KUTU KUCUK(KĞ)       SARF  1922\n",
      "19    3861    KAF.LIPTON LYL BAR.POS. 50 GR *12*     LIPTON  1918\n"
     ]
    }
   ],
   "source": [
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "od = (DATA_CLEAN / \"order_details_clean.parquet\").as_posix()\n",
    "cat = (DATA_CLEAN / \"categories_clean.parquet\").as_posix()\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Tỷ lệ dòng có unit_price = 0\n",
    "res1 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_all,\n",
    "  SUM(CASE WHEN unit_price = 0 THEN 1 ELSE 0 END) AS n_zero,\n",
    "  100.0 * SUM(CASE WHEN unit_price = 0 THEN 1 ELSE 0 END) / COUNT(*) AS pct_zero\n",
    "FROM parquet_scan('{od}');\n",
    "\"\"\").fetchdf()\n",
    "print(res1)\n",
    "\n",
    "# unit_price = 0 nhưng total_price > 0\n",
    "res2 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_sus,\n",
    "  SUM(total_price) AS sum_total_price_sus\n",
    "FROM parquet_scan('{od}')\n",
    "WHERE unit_price = 0 AND total_price > 0;\n",
    "\"\"\").fetchdf()\n",
    "print(res2)\n",
    "\n",
    "# unit_price = 0 và total_price = 0 (amount > 0)\n",
    "res3 = con.execute(f\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) AS n_free,\n",
    "  SUM(amount) AS qty_free\n",
    "FROM parquet_scan('{od}')\n",
    "WHERE unit_price = 0 AND total_price = 0 AND amount > 0;\n",
    "\"\"\").fetchdf()\n",
    "print(res3)\n",
    "\n",
    "# Top mặt hàng có unit_price = 0\n",
    "res4 = con.execute(f\"\"\"\n",
    "SELECT d.item_id, c.item_name, c.brand, COUNT(*) AS cnt\n",
    "FROM parquet_scan('{od}') d\n",
    "LEFT JOIN parquet_scan('{cat}') c ON d.item_id = c.item_id\n",
    "WHERE d.unit_price = 0\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY cnt DESC\n",
    "LIMIT 20;\n",
    "\"\"\").fetchdf()\n",
    "print(res4)\n",
    "\n",
    "con.close()\n",
    "\n",
    "# số lượng dòng có unit_price = 0 là 115638 - có thể là sản phẩm khuyến mãi hoặc nhập liệu sai\n",
    "# chiếm tỷ lệ ~0.22% trong toàn bộ dữ liệu (rất thấp nhưng không phải không đáng kể - tuy nhiên có thể drop nếu không ảnh hướng nhiều)\n",
    "\n",
    "# có 5346 trường hợp unit_price = 0 nhưng khách vẫn bị tính tiền vào sản phẩm đó (có thể là lỗi nhập liệu unit_price hoặc total_price hoặc một dạng khuyến mãi phức tạp)\n",
    "# khách đã chi 1.3M đơn vị tiền cho sản phẩm ở res2\n",
    "\n",
    "# hàng tặng kèm thật sự (unit_price và total_price đều bằng 0) có 110292 dòng\n",
    "# tổng số lượng sản phẩm free là 496407 sản phẩm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5edf53-30c2-472a-9689-745b65eae3bc",
   "metadata": {},
   "source": [
    "# **Merge file đích**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64cdcd-b809-4e8d-9355-600219fbcb77",
   "metadata": {},
   "source": [
    "Đây là file đích chỉ dùng để phân tích và khai phá dữ liệu\n",
    "\n",
    "Không tiền xử lý trên file này nữa, hoặc có (nếu dữ liệu vẫn chưa thật sự được sạch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f06130-97e9-4ef3-a542-81b5a8045015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu tạo file final_data.parquet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f8c80c5375440c8004045bac15f566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file final_data.parquet\n"
     ]
    }
   ],
   "source": [
    "DATA_CLEAN = Path(r\"C:\\Users\\pitou\\Desktop\\Data Mining\\data_clean\")\n",
    "final_fp = DATA_CLEAN / \"final_data.parquet\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print(\"Bắt đầu tạo file final_data.parquet...\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "    SELECT\n",
    "        -- Thông tin đơn hàng từ order_details và orders\n",
    "        od.order_id,\n",
    "        o.order_date,\n",
    "        o.order_year,\n",
    "        o.order_month,\n",
    "        o.order_weekday,\n",
    "        o.total_basket,\n",
    "        \n",
    "        -- Thông tin chi nhánh từ branches\n",
    "        o.branch_id,\n",
    "        b.region AS branch_region,\n",
    "        b.city AS branch_city,\n",
    "        b.town AS branch_town,\n",
    "        \n",
    "        -- Thông tin sản phẩm từ categories và order_details\n",
    "        od.item_id,\n",
    "        c.item_name,\n",
    "        c.category1,\n",
    "        c.category2,\n",
    "        c.category3,\n",
    "        c.category4,\n",
    "        c.brand,\n",
    "        od.amount,\n",
    "        od.unit_price,\n",
    "        od.total_price,\n",
    "        od.discount_amount, \n",
    "\n",
    "        -- Thông tin khách hàng \n",
    "        cust.user_id\n",
    "        \n",
    "    FROM parquet_scan('{(DATA_CLEAN / \"order_details_clean.parquet\").as_posix()}') AS od\n",
    "    \n",
    "    LEFT JOIN parquet_scan('{(DATA_CLEAN / \"orders_clean.parquet\").as_posix()}') AS o\n",
    "        ON od.order_id = o.order_id\n",
    "        \n",
    "    LEFT JOIN parquet_scan('{(DATA_CLEAN / \"branches_clean.parquet\").as_posix()}') AS b\n",
    "        ON o.branch_id = b.branch_id\n",
    "        \n",
    "    LEFT JOIN parquet_scan('{(DATA_CLEAN / \"categories_clean.parquet\").as_posix()}') AS c\n",
    "        ON od.item_id = c.item_id\n",
    "\n",
    "    -- Thêm JOIN với bảng customers\n",
    "    LEFT JOIN parquet_scan('{(DATA_CLEAN / \"customers_clean.parquet\").as_posix()}') AS cust\n",
    "        ON o.user_id = cust.user_id\n",
    "\n",
    ") TO '{final_fp.as_posix()}' (FORMAT 'parquet');\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "print(f\"Đã tạo file {final_fp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9509b6-32f0-457b-b237-f77e81eb16ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
